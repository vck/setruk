{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# projek setruk\n",
    "---\n",
    "\n",
    "*sebuah penelitian terhadap nama-nama orang yang sering dipakai di Indonesia dengan tujuan membuat mesin yang bisa membedakan jenis kelamin dari nama tersebut**\n",
    "\n",
    "                        Vicky Vernando Dasta - Hafizan Anas Sidiqi\n",
    "                        vickydasta@gmail.com   \n",
    "\n",
    "                                          veeklab \n",
    "                                         2016 - 2017\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## latar belakang\n",
    "\n",
    "- sering terjadi kesalahan interpretasi gender dari nama seseorang\n",
    "- diperlukannya mesin yang bisa melihat pola dan hubungan antara corpus dari nama dengan gendernya\n",
    "\n",
    "## teori\n",
    "\n",
    "*nama* dalam Kamus Besar Bahasa Indonesia berarti *kata untuk menyebut atau memanggil orang (tempat, barang, binatang, dan sebagainya)*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import sqlite3 as sqlite\n",
    "from pylab import *\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vickydasta/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/vickydasta/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    1\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    1\n",
       "26    0\n",
       "27    0\n",
       "28    1\n",
       "29    1\n",
       "Name:  gender, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data.csv\")\n",
    "\n",
    "# split data into test and train\n",
    "# 1:2\n",
    "\n",
    "train = df[11:30]\n",
    "test = df[0:10]\n",
    "\n",
    "test[\" gender\"] = test[\" gender\"].map({\" male\": 0, \" female\": 1})\n",
    "train[\" gender\"] = train[\" gender\"].map({\" male\": 0, \" female\": 1})\n",
    "\n",
    "label = train[\" gender\"]\n",
    "feature = train[\" name\"]\n",
    "len(label) == len(feature)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(feature)\n",
    "test = vectorizer.fit_transform([\"vicky nugroho\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 2 should be equal to 38, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-c228fa5300bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/vickydasta/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \"\"\"\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vickydasta/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/vickydasta/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    472\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    473\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    475\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 2 should be equal to 38, the number of features at training time"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setruk, Jan 3, 2017\n",
    "\n",
    "- cleaning data\n",
    "- import data to sqlite\n",
    "\n",
    "pada tahap ini, sudah terkumpul sebanyak 318 data (nama, jenis kelamin).\n",
    "selanjutnya dilakukan pembersihan terhadap data tersebut.\n",
    "\n",
    "tahap selanjutnya, dilakukan visualisasi terhadap nama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "f = open('data/data-2.csv', 'r')\n",
    "names = csv.reader(f)\n",
    "\n",
    "for name in names:\n",
    "    print name[0].lower(), \"0\" if name[1].lower() == \"m\" else \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "for name in csv.reader(open('data/data.csv')):\n",
    "    print name[1], name[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([' name',\n",
       "  ' vicky vernanndo dasta',\n",
       "  ' ahadiah ayu mulfa',\n",
       "  ' susilo bambang yudhoyono',\n",
       "  ' rudiantara',\n",
       "  ' gandhi wibowo',\n",
       "  ' hafizan annas sidiqhi',\n",
       "  ' joko widodo',\n",
       "  ' ibnu yahya',\n",
       "  ' muhammad rumli',\n",
       "  ' widya irfani',\n",
       "  ' bintang raezka ockland',\n",
       "  ' muhammad izzudin',\n",
       "  ' herdian prasetyo',\n",
       "  ' novinda ariani',\n",
       "  ' eka chandra',\n",
       "  ' rahmat hidayat',\n",
       "  ' gustin harianto',\n",
       "  ' tofik hidayat',\n",
       "  ' merry susilawati',\n",
       "  ' wadi zendrato',\n",
       "  ' advenrinus sababalat',\n",
       "  ' budi fernando',\n",
       "  ' robi ikhsan',\n",
       "  ' benny putra',\n",
       "  ' jufianto henri',\n",
       "  ' dinda pratiwi',\n",
       "  ' agung perwira',\n",
       "  ' didik sugianto',\n",
       "  ' mila cahyani',\n",
       "  ' winda wati wulandari',\n",
       "  'name',\n",
       "  'hafizhan shidqi',\n",
       "  'gandhi wibowo',\n",
       "  'aldio mahendra purwandrarto',\n",
       "  'benny putra',\n",
       "  'vicky vernando dasta',\n",
       "  'jufianto henri',\n",
       "  'aan nuraini',\n",
       "  'abdur rahman',\n",
       "  'abdurrahman, ms',\n",
       "  'ade indra sukma',\n",
       "  'ade irmayani',\n",
       "  'bakti yoga priyandana',\n",
       "  'daniel sepra pratama',\n",
       "  'dayu m sandro',\n",
       "  'dean mareti hariani',\n",
       "  'edi kurniawan wibowo',\n",
       "  'fadil rahmat andini',\n",
       "  'fahmi iqbal firmananda',\n",
       "  'fairuzi',\n",
       "  'gustian',\n",
       "  \"habil sabilla do'a\",\n",
       "  'hermawan syah',\n",
       "  'ibnuyohanzah ahmad',\n",
       "  'lia pertiwi',\n",
       "  'muhammad maksum sugondo',\n",
       "  'muhammad risfandanu',\n",
       "  'adnil riza',\n",
       "  'nadia gustiana',\n",
       "  'nanda aditya',\n",
       "  'nurgivo alfajri',\n",
       "  'pita irul sayekti',\n",
       "  'rahmadi gusri',\n",
       "  'rahmat',\n",
       "  'sadra wilis',\n",
       "  'said rio apriadi',\n",
       "  'tania rahmadhini',\n",
       "  'tarikhul mahfudz',\n",
       "  'vido idramedi',\n",
       "  'wahyu darmawan',\n",
       "  'yana pramana',\n",
       "  'yusrika dewi',\n",
       "  'zakiah nurviani',\n",
       "  'aditya dwi nugraha',\n",
       "  'afrian djugi',\n",
       "  'debby jayadi nugroho',\n",
       "  'dede dwi arviyanti',\n",
       "  'della maulina herianda',\n",
       "  'deny gustriansyah',\n",
       "  'desi fitri',\n",
       "  'edmund andriano',\n",
       "  'fajar aulia rahman',\n",
       "  'fathiya hasyifah sibarani',\n",
       "  'fauzar',\n",
       "  'habzer maisera',\n",
       "  'herzavina',\n",
       "  'ikbal gazalba',\n",
       "  'ikhsan firdaus',\n",
       "  'ilda ikhwana lubis',\n",
       "  'jayus suryawan',\n",
       "  'muhammad bagoes samaron',\n",
       "  'muhammad hanafi',\n",
       "  'muhammad ilham akbar khoiri',\n",
       "  'narendra benny',\n",
       "  'naufal abiyyu',\n",
       "  'nurhikmah',\n",
       "  'pradana bagus harsono',\n",
       "  'rahmi omya ulta',\n",
       "  'rahmi septhianingrum',\n",
       "  'rangga arief putra',\n",
       "  'rangga dwi nugrawan',\n",
       "  'saiful wahyudi',\n",
       "  'sari devia agustina',\n",
       "  'taufik oktafiyardi',\n",
       "  'teddy franwijaya',\n",
       "  'vigo farlandi',\n",
       "  'wahyu ernu setiawan',\n",
       "  'yofaldi laksmana putra',\n",
       "  'zubaidah',\n",
       "  'agus faturrahman',\n",
       "  'agustiando rahmat',\n",
       "  'aidil badri',\n",
       "  'alfajri',\n",
       "  'bayu hasan basyir aljawi',\n",
       "  'desi fransiska',\n",
       "  'desnando',\n",
       "  'desri ardika',\n",
       "  'dessy masdianata p',\n",
       "  'destria membrane',\n",
       "  'eka nur safitri',\n",
       "  'fauziah',\n",
       "  'feny afrisilia',\n",
       "  'hesty afriani srg',\n",
       "  'ilham afandi aziz',\n",
       "  'ilham fajri',\n",
       "  'indah permata sari',\n",
       "  'jukhri syahputra',\n",
       "  'm. muawam',\n",
       "  'm. yassir saputra jamina',\n",
       "  'mardiyyat fadliellah',\n",
       "  'mukhtar lutfi',\n",
       "  'nazarudin yusuf',\n",
       "  'neni anggraeni dalimunthe',\n",
       "  'nurpauliani dewi n',\n",
       "  'rano abdul rahman',\n",
       "  'ratih purwasih',\n",
       "  'raynaldi setiawan',\n",
       "  'shynta dwi afitri',\n",
       "  'siti romlah',\n",
       "  'teresno maulana',\n",
       "  'tessa eka pratiwi',\n",
       "  'wendi gusfan hutapea',\n",
       "  'yovita sari',\n",
       "  'zukri adinalta',\n",
       "  'alfi sahri',\n",
       "  'amalia wulandari',\n",
       "  'amelia novrida',\n",
       "  'andre ganda wilaga putra',\n",
       "  'andre oktora',\n",
       "  'benni setiawan',\n",
       "  'deswanto',\n",
       "  'desy syahputri',\n",
       "  'eka wulandari',\n",
       "  'ferry ramadhan',\n",
       "  'firdaus',\n",
       "  'hamdani asril',\n",
       "  'hijrah syahputra',\n",
       "  'indah rahmawati',\n",
       "  'indra firman',\n",
       "  'indri dian pertiwi',\n",
       "  'kemal pasha',\n",
       "  'muhammad sayuti nur nasution',\n",
       "  'miftahur ridho',\n",
       "  'mila yuli yanti',\n",
       "  'muhammad wendi hidayat',\n",
       "  'nikawati',\n",
       "  'nofan widiyarna',\n",
       "  'nurudin rahman',\n",
       "  'puji astuti',\n",
       "  'refi delia',\n",
       "  'reno mulia sari',\n",
       "  'resa putri ananda',\n",
       "  'resi septiani',\n",
       "  'rudi kurniawan',\n",
       "  'siti zulaiha',\n",
       "  'sry dhina pohan',\n",
       "  'thovanni jogga',\n",
       "  'tian fitra kurniawan',\n",
       "  'widya ayu azhari',\n",
       "  'yudiatma adrion',\n",
       "  'zukri rahman',\n",
       "  'andre saputra',\n",
       "  'andrianto',\n",
       "  'andryan dwi cahyono',\n",
       "  'angga wiratama',\n",
       "  'anggi desmita arini',\n",
       "  'dewi cita rani',\n",
       "  'dewi kartika sari',\n",
       "  'dewi shinta octariati',\n",
       "  'firdaus',\n",
       "  'fitra andri gunawan',\n",
       "  'indriani saritsha',\n",
       "  'inggar wangi r',\n",
       "  'mira afriani',\n",
       "  'muhammad adri',\n",
       "  'muhammad alayyubi',\n",
       "  'nony chrisnayanti',\n",
       "  'nora ferwati',\n",
       "  'nurul gayatri indah reza',\n",
       "  'benny yohanes',\n",
       "  'elennuari',\n",
       "  'harika vaizal',\n",
       "  'hildayanti oktaviana',\n",
       "  'khairul fahmi purba',\n",
       "  'muhammad triyoga sp',\n",
       "  'putri lia lestari',\n",
       "  'resti yulia',\n",
       "  'reysa hastarimasuci',\n",
       "  'reza fahlevi',\n",
       "  'rhesma naca',\n",
       "  'rudi wijaya',\n",
       "  'suci fahma julia',\n",
       "  'suci hijryani fitry',\n",
       "  'tika handayani asnur',\n",
       "  'tio doli raharjo',\n",
       "  'winda wahyuti',\n",
       "  'yulia ningsih',\n",
       "  'anggia anfina',\n",
       "  'anita pauzia hsb',\n",
       "  'annisa julita sari',\n",
       "  'boby adi oktarino',\n",
       "  'dias marzal pratama',\n",
       "  'dicky mahendra',\n",
       "  'dika aristya linardi',\n",
       "  'elvi suryani',\n",
       "  'fitra miswardi',\n",
       "  'fitri meldiani',\n",
       "  'husnul habib',\n",
       "  'irfani dwi ayu riski',\n",
       "  'irpandi kurniawan',\n",
       "  'kurniawan eka putra',\n",
       "  'muhammad asri wisnu wardana',\n",
       "  'muhammad audi reza islami',\n",
       "  'muhammad azmeer',\n",
       "  'muhammad thoha',\n",
       "  'novi gustiana',\n",
       "  'novia kumala sari',\n",
       "  'padli nofrizal',\n",
       "  'putri wahyuni',\n",
       "  'rahmat hidayat',\n",
       "  'rahmi andreni',\n",
       "  'rian aries fani',\n",
       "  'riandi selvi',\n",
       "  'rianto',\n",
       "  'ridha ulva',\n",
       "  'rizqi wahyuningsih',\n",
       "  'ruwadi saputra',\n",
       "  'sugeng hermawan',\n",
       "  'suliatun',\n",
       "  'tomi ismeidianto',\n",
       "  'usthalay putra',\n",
       "  'winggo aga septian',\n",
       "  'yunaldi rizki putra',\n",
       "  'arif prasetyo',\n",
       "  'arie rahman satria',\n",
       "  'arinda oktaviana',\n",
       "  'asri jakawendra',\n",
       "  'astri stiawaty',\n",
       "  'aszani',\n",
       "  'boby rahman',\n",
       "  'dewi cahyati',\n",
       "  'dimas aditya perdana',\n",
       "  'dinda afani',\n",
       "  'doni sanjaya',\n",
       "  'fitri yanti',\n",
       "  'hendri eka saputra',\n",
       "  'irwan ahmad gafur',\n",
       "  'isa ismail',\n",
       "  'kurniawan rosman a',\n",
       "  'muhammad azmy',\n",
       "  'muhammad ilham',\n",
       "  'muhammad sholihan',\n",
       "  'novita dewi',\n",
       "  'novri sabli saputra',\n",
       "  'pajar bahari',\n",
       "  'redha fauziah aziz',\n",
       "  'ridho',\n",
       "  'ridho fajri',\n",
       "  'ridho rismayanda',\n",
       "  'ridwan candra',\n",
       "  'rosdina',\n",
       "  'supriadi',\n",
       "  'suriyani',\n",
       "  'tommy zul hidayat',\n",
       "  'umi riyani',\n",
       "  'wiwik sumarmi',\n",
       "  'yuni dwi hastuti',\n",
       "  'aulia rahman',\n",
       "  'agung kurniawan',\n",
       "  'ahmad fauzi paturusi',\n",
       "  'arie biola gunti masuko',\n",
       "  'ayu andira',\n",
       "  'ayu dwi septiana arta',\n",
       "  'azwar anas',\n",
       "  'azwir irfan nanda',\n",
       "  'budi setiawan',\n",
       "  'donna febriani',\n",
       "  'dwi widiastuti',\n",
       "  'dwiki apsyarin',\n",
       "  'dwiza indri',\n",
       "  'frans b jaya zalukhu',\n",
       "  'fuad harisfa',\n",
       "  'herman efendi',\n",
       "  'ichsyan rizky adi p',\n",
       "  'ivo oktavianti',\n",
       "  'lailatul izzati',\n",
       "  'muhammad oki',\n",
       "  'muhammad ridho ardonis',\n",
       "  'muhammad rizqi muttaqin',\n",
       "  'muhammad setyo',\n",
       "  'nur aulia hasanah',\n",
       "  'nurfatrianti',\n",
       "  'pikril islami',\n",
       "  'rikal',\n",
       "  'riyan hidayat',\n",
       "  'rizki pratama',\n",
       "  'rizkie hafizzah',\n",
       "  'syaiful akbar',\n",
       "  'tri puspita darmayuli'],\n",
       " [1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data into train and test with proportion 1:4\n",
    "\n",
    "name_test = token[0: 80]\n",
    "gender_test = gender[0: 80]\n",
    "\n",
    "gender_train = gender[80: 320]\n",
    "name_train = token[80: 320]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "\n",
    "vectorizer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Scatter, output_file, show\n",
    "from bokeh.sampledata.autompg import autompg as df\n",
    "\n",
    "p = Scatter(df, x='mpg', y='hp', color='cyl', title=\"HP vs MPG (shaded by CYL)\",\n",
    "            xlabel=\"Miles Per Gallon\", ylabel=\"Horsepower\")\n",
    "\n",
    "output_file(\"scatter.html\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con = sqlite3.connect(\"setruk-2.db\")\n",
    "df = pd.read_sql(\"SELECT * FROM dist_name WHERE sum > 4 and gender=0\", con)\n",
    "df2 = pd.read_sql(\"SELECT * FROM dist_name WHERE sum > 4 and gender=1\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_sql(\"SELECT * FROM dist_name WHERE sum > 4 and gender=1\", con)\n",
    "token = [token.encode('ascii') for token in df2['token']]\n",
    "token_sum = [x for x in df2['sum']]\n",
    "gender = [gender for gender in df]\n",
    "import csv\n",
    "\n",
    "f = open('data.csv', 'a+')\n",
    "\n",
    "csv_writer = csv.writer(f)\n",
    "\n",
    "csv_writer.writerow(('token', 'freq'))\n",
    "for i in range(len(token)):\n",
    "    csv_writer.writerow((token[i], token_sum[i]))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5  1.5  2.5  3.5  4.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "val = 3+10*rand(5)    # the bar lengths\n",
    "pos = arange(5)+.5    # the bar centers on the y axis\n",
    "\n",
    "\n",
    "barh(pos,val, align='center')\n",
    "yticks(pos, ('Tom', 'Dick', 'Harry', 'Slim', 'Jim'))\n",
    "xlabel('Performance')\n",
    "title('How fast do you want to go today?')\n",
    "\n",
    "\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Januari, 2017\n",
    "\n",
    "using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "f = open('data/namanama.csv', 'r')\n",
    "\n",
    "csvr = csv.reader(f)\n",
    "\n",
    "for d in csvr:\n",
    "    print d\n",
    "\n",
    "f = open('data/namanama.csv', 'r')\n",
    "\n",
    "csvr = csv.reader(f)\n",
    "\n",
    "name, gender = [], []\n",
    "\n",
    "for data in csvr:\n",
    "    n, g = data[0].split(';')\n",
    "    name.append(n)\n",
    "    gender.append(g)\n",
    "    \n",
    "\n",
    "data = zip(name, gender)\n",
    "\n",
    "f = open('data/new-data.csv','a+')\n",
    "\n",
    "csvwriter = csv.writer(f)\n",
    "csvwriter.writerow(('name', 'gender'))\n",
    "\n",
    "\n",
    "for item in data:\n",
    "    csvwriter.writerow(item)\n",
    "\n",
    "df = pd.read_csv('data/new-data.csv')\n",
    "\n",
    "df['name']\n",
    "df['gender']\n",
    "df['name']\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'float' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-1fef5dec7f2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpun\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpunct\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpun\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'float' is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sqlite\n",
    "\n",
    "\n",
    "db = sqlite.connect('setruk-2.db')\n",
    "cur = db.cursor()\n",
    "\n",
    "df = pd.read_csv('data/new-data.csv')\n",
    "df = df[df.name != 'nama']\n",
    "\n",
    "punct = [\"\"\"',.\"\"\"]\n",
    "\n",
    "names = []\n",
    "\n",
    "for name in df.name:\n",
    "    for pun in punct:\n",
    "        if pun in name.split(:\n",
    "            name.replace(pun, '')\n",
    "    names.append(name)\n",
    "    \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "\n",
    "gender = [gender for gender in df.gender]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "\n",
    "vectorizer = tfidf(ngram_range=(1,3))\n",
    "\n",
    "\n",
    "\n",
    "df2 = pd.read_sql(\"SELECT * FROM names\", con)\n",
    "token = [token.encode('ascii').replace(' ', '') for token in df2['name']]\n",
    "gender = [int(gender.encode('ascii')) for gender in df2['gender']]\n",
    "\n",
    "\n",
    "name_test = token[0: 80]\n",
    "gender_test = gender[0: 80]\n",
    "\n",
    "gender_train = gender[80: 320]\n",
    "name_train = token[80: 320]\n",
    "\n",
    "\n",
    "train_x = vectorizer.fit_transform(name_train)\n",
    "\n",
    "test_x = vectorizer.fit_transform(name_test)\n",
    "\n",
    "model = LR()\n",
    "model.fit(train_x, gender_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score() takes at least 3 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-947dc094bc6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: score() takes at least 3 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "model.pre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
